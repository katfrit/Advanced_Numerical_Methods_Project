{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from Wolfe_line_search import wolfe_line_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Broyden-CG with Wolfe line search\n",
    "def broyden_cg_with_wolfe(f, grad_f, x0, tol=1e-6, max_iter=5000):\n",
    "    x = x0\n",
    "    n = len(x0)\n",
    "    B = np.eye(n)  # Initial Hessian approximation\n",
    "    g = grad_f(x)\n",
    "    p = -g  # Initial search direction\n",
    "    iter_count = 0\n",
    "\n",
    "    while np.linalg.norm(g) > tol and iter_count < max_iter:\n",
    "        iter_count += 1\n",
    "        \n",
    "        # Perform Wolfe line search to find alpha\n",
    "        alpha = wolfe_line_search(f, grad_f, x, p)\n",
    "\n",
    "        # Update x\n",
    "        x_new = x + alpha * p\n",
    "\n",
    "        # Update gradient\n",
    "        g_new = grad_f(x_new)\n",
    "\n",
    "\n",
    "        # Compute s and y for Broyden update\n",
    "        s = x_new - x\n",
    "        y = g_new - g\n",
    "\n",
    "        # Update B (Broyden's rank-one update)\n",
    "        Bs = B @ s\n",
    "        B += np.outer(y - Bs, s) / np.dot(s, s)\n",
    "\n",
    "        # Update direction p using Conjugate Gradient formula\n",
    "        p = -np.linalg.solve(B, g_new)\n",
    "\n",
    "        # Prepare for the next iteration\n",
    "        x = x_new\n",
    "        g = g_new\n",
    "\n",
    "    return x, f(x), iter_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized x: [1. 2.]\n",
      "Function value at minimum: 0.0\n",
      "Iterations: 1\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Define the function and its gradient\n",
    "    def f(x):\n",
    "        return (x[0] - 1)**2 + (x[1] - 2)**2\n",
    "\n",
    "    def grad_f(x):\n",
    "        return np.array([2 * (x[0] - 1), 2 * (x[1] - 2)])\n",
    "\n",
    "    # Initial guess\n",
    "    x0 = np.array([2.0, 1.0])\n",
    "\n",
    "    # Run the Broyden-CG algorithm with Wolfe line search\n",
    "    x_opt, f_val, iterations = broyden_cg_with_wolfe(f, grad_f, x0)\n",
    "\n",
    "    print(f\"Optimized x: {x_opt}\")\n",
    "    print(f\"Function value at minimum: {f_val}\")\n",
    "    print(f\"Iterations: {iterations}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized x: [0.676534   0.45844332]\n",
      "Function value at minimum: 0.10468576273582657\n",
      "Iterations: 5000\n"
     ]
    }
   ],
   "source": [
    "# Define the Rosenbrock function and its gradient\n",
    "def rosenbrock(x):\n",
    "    return (1 - x[0])**2 + 100 * (x[1] - x[0]**2)**2\n",
    "\n",
    "def grad_rosenbrock(x):\n",
    "    grad_x0 = -2 * (1 - x[0]) - 400 * x[0] * (x[1] - x[0]**2)\n",
    "    grad_x1 = 200 * (x[1] - x[0]**2)\n",
    "    return np.array([grad_x0, grad_x1])\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Initial guess\n",
    "    x0 = np.array([-1.2, 1.0])\n",
    "\n",
    "    # Run the Broyden-CG algorithm with Wolfe line search\n",
    "    x_opt, f_val, iterations = broyden_cg_with_wolfe(rosenbrock, grad_rosenbrock, x0)\n",
    "\n",
    "    print(f\"Optimized x: {x_opt}\")\n",
    "    print(f\"Function value at minimum: {f_val}\")\n",
    "    print(f\"Iterations: {iterations}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized x: [-14.63565282 -14.63565282]\n",
      "Function value at minimum: 8.807380048980865e-07\n",
      "Iterations: 20\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the exponential test function\n",
    "def exponential_function(x):\n",
    "    \"\"\"\n",
    "    Exponential test function: f(x, y) = exp(x) + exp(y)\n",
    "    \"\"\"\n",
    "    return np.exp(x[0]) + np.exp(x[1])\n",
    "\n",
    "# Define the gradient of the exponential test function\n",
    "def grad_exponential_function(x):\n",
    "    \"\"\"\n",
    "    Gradient of the exponential test function: grad(f) = [exp(x), exp(y)]\n",
    "    \"\"\"\n",
    "    grad_x0 = np.exp(x[0])\n",
    "    grad_x1 = np.exp(x[1])\n",
    "    return np.array([grad_x0, grad_x1])\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Initial guess\n",
    "    x0 = np.array([-1.0, -1.0])\n",
    "\n",
    "    # Example function calls to hypothetical optimization methods\n",
    "    # Ensure that `smabfgs`, `gradient_descent`, and `broyden_cg` are implemented or imported\n",
    "    x_opt, f_val, iterations = broyden_cg_with_wolfe(exponential_function, grad_exponential_function, x0)\n",
    "\n",
    "    print(f\"Optimized x: {x_opt}\")\n",
    "    print(f\"Function value at minimum: {f_val}\")\n",
    "    print(f\"Iterations: {iterations}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized x: [1.5707963  3.14159271]\n",
      "Function value at minimum: -0.999999999999998\n",
      "Iterations: 9\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the non-convex test function\n",
    "def non_convex_function(x):\n",
    "    \"\"\"\n",
    "    Non-convex test function: f(x, y) = sin(x) * cos(y)\n",
    "    \"\"\"\n",
    "    return np.sin(x[0]) * np.cos(x[1])\n",
    "\n",
    "# Define the gradient of the non-convex test function\n",
    "def grad_non_convex_function(x):\n",
    "    \"\"\"\n",
    "    Gradient of the non-convex test function:\n",
    "    grad(f) = [cos(x) * cos(y), -sin(x) * sin(y)]\n",
    "    \"\"\"\n",
    "    grad_x0 = np.cos(x[0]) * np.cos(x[1])  # Partial derivative w.r.t. x\n",
    "    grad_x1 = -np.sin(x[0]) * np.sin(x[1])  # Partial derivative w.r.t. y\n",
    "    return np.array([grad_x0, grad_x1])\n",
    "\n",
    "# Define the Hessian of the non-convex test function\n",
    "def hess_non_convex_function(x):\n",
    "    \"\"\"\n",
    "    Hessian of the non-convex test function:\n",
    "    The second derivatives:\n",
    "    H[0,0] = -sin(x) * cos(y)\n",
    "    H[1,1] = -sin(x) * cos(y)\n",
    "    H[0,1] = -cos(x) * sin(y)\n",
    "    H[1,0] = -cos(x) * sin(y)\n",
    "    \"\"\"\n",
    "    hess_x0x0 = -np.sin(x[0]) * np.cos(x[1])  # Second partial derivative w.r.t. x\n",
    "    hess_x1x1 = -np.sin(x[0]) * np.cos(x[1])  # Second partial derivative w.r.t. y\n",
    "    hess_x0x1 = -np.cos(x[0]) * np.sin(x[1])  # Mixed partial derivative\n",
    "    hess_x1x0 = hess_x0x1  # Symmetry of the Hessian\n",
    "    return np.array([[hess_x0x0, hess_x0x1], [hess_x1x0, hess_x1x1]])\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Initial guess\n",
    "    x0 = np.array([1.0, 1.0])\n",
    "\n",
    "    # Example function calls to hypothetical optimization methods\n",
    "    # Ensure that `smabfgs`, `gradient_descent`, and `broyden_cg` are implemented or imported\n",
    "    x_opt, f_val, iterations = broyden_cg_with_wolfe(non_convex_function, grad_non_convex_function, x0)\n",
    "\n",
    "    print(f\"Optimized x: {x_opt}\")\n",
    "    print(f\"Function value at minimum: {f_val}\")\n",
    "    print(f\"Iterations: {iterations}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MaPro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
